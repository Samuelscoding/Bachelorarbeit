{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datensatz-Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports und Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmium as osm\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from collections import Counter, defaultdict\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import xml.etree.ElementTree as ET\n",
    "from matplotlib.lines import Line2D\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Setze den Pfad zum Dataset\n",
    "dataset_path = os.path.join(\"Datasets\", \"unterfranken-latest.osm\")\n",
    "cities = [\"Ringheim\", \"Mömlingen\", \"Glattbach\", \"Großostheim\", \"Marktheidenfeld\", \"Aschaffenburg\", \"Würzburg\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten in XML-Datei speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_xml(df, city_name, addresstype):\n",
    "    root = ET.Element(\"osm\", version=\"0.6\", generator=\"Bachelorproject\")\n",
    "    \n",
    "    # Knoten hinzufügen\n",
    "    for _, row in df[df['type'] == 'node'].iterrows():\n",
    "        node = ET.SubElement(root, \"node\", id=str(row['id']),\n",
    "                             visible=str(row['visible']),\n",
    "                             lat=str(row['latitude']),\n",
    "                             lon=str(row['longitude']))\n",
    "        if row['tagkey']:\n",
    "            ET.SubElement(node, \"tag\", k=row['tagkey'], v=row['tagvalue'])\n",
    "    \n",
    "    # Wege hinzufügen\n",
    "    for _, row in df[df['type'] == 'way'].iterrows():\n",
    "        way_attrs = {\n",
    "            \"id\": str(row['id']),\n",
    "            \"visible\": str(row['visible'])\n",
    "        }\n",
    "        # Wenn eine Länge vorhanden ist, als Attribut hinzufügen\n",
    "        if 'length' in row and pd.notna(row['length']):\n",
    "            way_attrs['length'] = str(row['length'])\n",
    "        \n",
    "        way = ET.SubElement(root, \"way\", **way_attrs)\n",
    "        \n",
    "        for node_id in row['node_ids']:\n",
    "            ET.SubElement(way, \"nd\", ref=str(node_id))\n",
    "        \n",
    "        if row['tagkey']:\n",
    "            ET.SubElement(way, \"tag\", k=row['tagkey'], v=row['tagvalue'])\n",
    "\n",
    "    # XML-Baum erstellen und speichern\n",
    "    city_folder = os.path.join(\"City_data\", addresstype)\n",
    "    os.makedirs(city_folder, exist_ok=True)\n",
    "    \n",
    "    tree = ET.ElementTree(root)\n",
    "    file_path = os.path.join(city_folder, f\"{city_name}.osm\")\n",
    "    tree.write(file_path, encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(f\"Datei erfolgreich gespeichert: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten aus der XML-Datei lesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_xml(city_name, addresstype):\n",
    "    file_path = os.path.join(\"City_data\", addresstype,f\"{city_name}.osm\")\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    osm_data = []\n",
    "\n",
    "    # Knoten extrahieren\n",
    "    for node in root.findall(\"node\"):\n",
    "        node_id = int(node.get(\"id\"))\n",
    "        lon = float(node.get(\"lon\"))\n",
    "        lat = float(node.get(\"lat\"))\n",
    "        osm_data.append([\"node\", node_id, True, 0, None, None, lon, lat, None])\n",
    "\n",
    "    # Wege extrahieren\n",
    "    for way in root.findall(\"way\"):\n",
    "        way_id = int(way.get(\"id\"))\n",
    "        node_ids = [int(nd.get(\"ref\")) for nd in way.findall(\"nd\")]\n",
    "        for tag in way.findall(\"tag\"):\n",
    "            tagkey = tag.get(\"k\")\n",
    "            tagvalue = tag.get(\"v\")\n",
    "            osm_data.append([\"way\", way_id, True, len(way.findall(\"tag\")), tagkey, tagvalue, None, None, node_ids])\n",
    "\n",
    "    # DataFrame erstellen\n",
    "    columns = ['type', 'id', 'visible', 'ntags', 'tagkey', 'tagvalue', 'longitude', 'latitude', 'node_ids']\n",
    "    return pd.DataFrame(osm_data, columns=columns)\n",
    "\n",
    "def load_from_xml_with_length(city_name, addresstype):\n",
    "    file_path = os.path.join(\"City_data\", addresstype,f\"{city_name}.osm\")\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    osm_data = []\n",
    "\n",
    "    # Knoten extrahieren\n",
    "    for node in root.findall(\"node\"):\n",
    "        node_id = int(node.get(\"id\"))\n",
    "        lon = float(node.get(\"lon\"))\n",
    "        lat = float(node.get(\"lat\"))\n",
    "        osm_data.append([\"node\", node_id, True, 0, None, None, lon, lat, None])\n",
    "\n",
    "    # Wege extrahieren\n",
    "    for way in root.findall(\"way\"):\n",
    "        way_id = int(way.get(\"id\"))\n",
    "        node_ids = [int(nd.get(\"ref\")) for nd in way.findall(\"nd\")]\n",
    "        length = way.get(\"length\")  \n",
    "        length = float(length) if length else None  \n",
    "        for tag in way.findall(\"tag\"):\n",
    "            tagkey = tag.get(\"k\")\n",
    "            tagvalue = tag.get(\"v\")\n",
    "            osm_data.append([\"way\", way_id, True, len(way.findall(\"tag\")), tagkey, tagvalue, None, None, node_ids, length])\n",
    "\n",
    "    # DataFrame erstellen\n",
    "    columns = ['type', 'id', 'visible', 'ntags', 'tagkey', 'tagvalue', 'longitude', 'latitude', 'node_ids', 'length']\n",
    "    return pd.DataFrame(osm_data, columns=columns)\n",
    "\n",
    "def load_from_all_xml(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    osm_data = []\n",
    "\n",
    "    # Knoten extrahieren\n",
    "    for node in root.findall(\"node\"):\n",
    "        node_id = int(node.get(\"id\"))\n",
    "        lon = float(node.get(\"lon\"))\n",
    "        lat = float(node.get(\"lat\"))\n",
    "        osm_data.append([\"node\", node_id, True, 0, None, None, lon, lat, None])\n",
    "\n",
    "    # Wege extrahieren\n",
    "    for way in root.findall(\"way\"):\n",
    "        way_id = int(way.get(\"id\"))\n",
    "        node_ids = [int(nd.get(\"ref\")) for nd in way.findall(\"nd\")]\n",
    "        length = way.get(\"length\")  \n",
    "        length = float(length) if length else None  \n",
    "        for tag in way.findall(\"tag\"):\n",
    "            tagkey = tag.get(\"k\")\n",
    "            tagvalue = tag.get(\"v\")\n",
    "            osm_data.append([\"way\", way_id, True, len(way.findall(\"tag\")), tagkey, tagvalue, None, None, node_ids, length])\n",
    "\n",
    "    # DataFrame erstellen\n",
    "    columns = ['type', 'id', 'visible', 'ntags', 'tagkey', 'tagvalue', 'longitude', 'latitude', 'node_ids', 'length']\n",
    "    return pd.DataFrame(osm_data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haversine-Formel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # Dezimalzahlen in Radianten umwandeln\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine Formel\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius der Erde in Kilometer\n",
    "    return c * r * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Straßenlängen berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straßenlänge berechnen\n",
    "def calculate_full_road_length(way_row, df_nodes):\n",
    "    node_ids = way_row['node_ids']\n",
    "    total_length = 0\n",
    "\n",
    "    for i in range(len(node_ids) - 1):\n",
    "        first_node = df_nodes[df_nodes['id'] == node_ids[i]]\n",
    "        second_node = df_nodes[df_nodes['id'] == node_ids[i + 1]]\n",
    "\n",
    "        # Überprüfung, ob beide Knoten existieren\n",
    "        if first_node.empty or second_node.empty:\n",
    "            return None\n",
    "\n",
    "        total_length += haversine(\n",
    "            first_node['longitude'].values[0], first_node['latitude'].values[0],\n",
    "            second_node['longitude'].values[0], second_node['latitude'].values[0]\n",
    "        )\n",
    "\n",
    "    return total_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Außerstehende Knoten entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_highway_nodes(df):\n",
    "    # Filtere nur die 'way'-Elemente mit tagkey 'highway'\n",
    "    highway_ways = df[(df['type'] == 'way') & (df['tagkey'] == 'highway')]\n",
    "\n",
    "    # Extrahiere alle referenzierten node_ids aus diesen Wegen\n",
    "    highway_node_ids = []\n",
    "    for node_ids_list in highway_ways['node_ids']:\n",
    "        if node_ids_list is not None:\n",
    "            highway_node_ids.extend(node_ids_list)\n",
    "\n",
    "    # Behalte nur Nodes, die in diesen 'highway'-Wegen vorkommen\n",
    "    df_nodes_filtered = df[(df['type'] == 'node') & (df['id'].isin(highway_node_ids))]\n",
    "\n",
    "    # Kombiniere die gefilterten 'way' und 'node'-Elemente\n",
    "    filtered_data = pd.concat([highway_ways, df_nodes_filtered], ignore_index=True)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knoten vom Grad 2 entfernen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funktionen für die Bearbeitung der Grad 2 Knoten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_found = {}\n",
    "\n",
    "# Entfernen von Knoten mit Grad 2 aus den node-ids\n",
    "def remove_degree_2_nodes(node_ids, degree_2_node_ids):\n",
    "    if node_ids is not None:\n",
    "        return [node_id for node_id in node_ids if node_id not in degree_2_node_ids]\n",
    "    return node_ids\n",
    "\n",
    "# 2 Grad-3+-Nachbarn finden\n",
    "def find_neighbors_with_degree_3(G, node_id, visited=None, found_neighbors=None):    \n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if found_neighbors is None:\n",
    "        found_neighbors = []\n",
    "\n",
    "    visited.add(node_id)\n",
    "    neighbors = list(G.neighbors(node_id))\n",
    "\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor not in visited:\n",
    "            neighbor_degree = G.degree(neighbor)\n",
    "\n",
    "            # Füge Nachbarn hinzu, wenn er Grad 3 oder höher hat\n",
    "            if neighbor_degree == 1 or neighbor_degree >= 3:\n",
    "                found_neighbors.append(neighbor)\n",
    "\n",
    "                if node_id not in neighbors_found:\n",
    "                    neighbors_found[node_id] = []\n",
    "                neighbors_found[node_id].append(neighbor)\n",
    "\n",
    "                # Stoppe, wenn zwei passende Nachbarn gefunden wurden\n",
    "                if len(found_neighbors) == 2:\n",
    "                    return found_neighbors\n",
    "\n",
    "            # Rekursive Suche fortsetzen, wenn der Nachbar Grad 2 hat\n",
    "            elif neighbor_degree == 2:\n",
    "                result = find_neighbors_with_degree_3(G, neighbor, visited, found_neighbors)\n",
    "                if len(result) == 2:\n",
    "                    return result\n",
    "                \n",
    "    return found_neighbors\n",
    "\n",
    "# Aktualisieren der node_ids der Straßen, die Knoten mit Grad 2 enthalten\n",
    "def update_node_ids(G, row, degree_2_node_ids, ways_filter):\n",
    "    node_ids = row['node_ids']\n",
    "    if node_ids is not None:\n",
    "        updated_node_ids = list(node_ids)\n",
    "        for node_id in node_ids:\n",
    "            if node_id in degree_2_node_ids:\n",
    "                # Finde Nachbarn des Knotens mit Grad 2\n",
    "                neighbors = find_neighbors_with_degree_3(G, node_id)\n",
    "                if len(neighbors) == 2:\n",
    "                    neighbor_1, neighbor_2 = neighbors\n",
    "\n",
    "                    # Finde die zwei Straßen, die den Grad-2-Knoten referenzieren\n",
    "                    referencing_ways = ways_filter[ways_filter['node_ids'].apply(lambda x: node_id in x)]\n",
    "\n",
    "                    if len(referencing_ways) == 2:\n",
    "                        way_1, way_2 = referencing_ways.iloc[0], referencing_ways.iloc[1]\n",
    "\n",
    "                        # Kopiere die Node-IDs als Listen\n",
    "                        way_1_node_ids = list(way_1['node_ids']) if isinstance(way_1['node_ids'], list) else way_1['node_ids']\n",
    "                        way_2_node_ids = list(way_2['node_ids']) if isinstance(way_2['node_ids'], list) else way_2['node_ids']\n",
    "\n",
    "                        # Füge Nachbarn hinzu, falls sie nicht bereits vorhanden sind\n",
    "                        if neighbor_1 not in way_2_node_ids:\n",
    "                            way_2_node_ids.append(neighbor_1)\n",
    "                        if neighbor_1 not in way_1_node_ids:\n",
    "                            way_1_node_ids.append(neighbor_1)\n",
    "\n",
    "                        # Aktualisiere die DataFrame-Zeilen\n",
    "                        ways_filter.at[way_1.name, 'node_ids'] = way_1_node_ids\n",
    "                        ways_filter.at[way_2.name, 'node_ids'] = way_2_node_ids\n",
    "\n",
    "        # Stelle sicher, dass die Rückgabewerte korrekt sind\n",
    "        return updated_node_ids if updated_node_ids else None\n",
    "    return node_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufruf zum Entfernen der Grad-2-Knoten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_degree_2_nodes_from_file(df, ways_filter):\n",
    "    # Extrahieren der Knoten_Ids\n",
    "    existing_node_ids = set(df[df['type'] == 'node']['id'])\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for index, row in df[df['type'] == 'node'].iterrows():  \n",
    "        G.add_node(row['id'], pos=(row['longitude'], row['latitude']))\n",
    "\n",
    "    # Wege durchgehen und Kanten im Graphen hinzufügen\n",
    "    for _, row in df[df['type'] == 'way'].iterrows():\n",
    "        node_ids = row['node_ids']\n",
    "        if node_ids is not None:\n",
    "            valid_node_ids = [node_id for node_id in node_ids if node_id in existing_node_ids]\n",
    "            for i in range(len(valid_node_ids) - 1):\n",
    "                G.add_edge(valid_node_ids[i], valid_node_ids[i + 1])\n",
    "\n",
    "    # Knoten mit Grad 2 finden\n",
    "    node_degrees = dict(G.degree())\n",
    "    nodes_with_degree_2 = [node_id for node_id, degree in node_degrees.items() if degree == 2]\n",
    "\n",
    "    # Knoten mit Grad 2 in filtered_data_multiple filtern\n",
    "    df_nodes_degree_2 = df[(df['type'] == 'node') & (df['id'].isin(nodes_with_degree_2))]\n",
    "    degree_2_node_ids = set(df_nodes_degree_2['id'])\n",
    "\n",
    "    # Aktualisiere die node_ids der Straßen\n",
    "    df['node_ids'] = df.apply(lambda row: update_node_ids(G, row, degree_2_node_ids, ways_filter), axis=1)\n",
    "\n",
    "    # Entfernen der Knoten mit Grad 2 aus den node_ids der Straßen\n",
    "    df['node_ids'] = df['node_ids'].apply(lambda node_ids: remove_degree_2_nodes(node_ids, degree_2_node_ids.union(degree_2_node_ids)))\n",
    "\n",
    "    # Entferne Knoten mit Grad 2 aus dem Datensatz\n",
    "    df = df[~df['id'].isin(degree_2_node_ids.union(degree_2_node_ids))]\n",
    "\n",
    "    G.remove_nodes_from(nodes_with_degree_2)\n",
    "\n",
    "    # Entferne unverbundene Knoten aus dem Datensatz\n",
    "    connected_nodes = set(G.nodes)\n",
    "    df = df[(df['type'] != 'node') | (df['id'].isin(connected_nodes))]\n",
    "    isolated_nodes = [node for node, degree in G.degree() if degree == 0]\n",
    "    df = df[~((df['type'] == 'node') & (df['id'].isin(isolated_nodes)))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knoten zusammenfügen, die nah beieinander stehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_merging(df, max_distance=5):\n",
    "    df_nodes = df[df['type'] == 'node']\n",
    "    df_ways = df[df['type'] == 'way']\n",
    "\n",
    "    merged_nodes, node_merge_dict = merge_within_distance(df_nodes, max_distance)\n",
    "    df_merged_nodes = pd.DataFrame(merged_nodes, columns=['id', 'longitude', 'latitude'])\n",
    "\n",
    "    # Wege aktualisieren\n",
    "    df_ways['node_ids'] = df_ways['node_ids'].apply(\n",
    "        lambda x: update_node_ids_merged(x, node_merge_dict)\n",
    "    )\n",
    "    # Ehemalige Knoten entfernen\n",
    "    df_nodes_updated = remove_replaced_nodes(df_nodes, node_merge_dict)\n",
    "\n",
    "    df_nodes_final = pd.concat([df_nodes_updated, df_merged_nodes], ignore_index=True)\n",
    "\n",
    "    # Doppelte und leere Knoten-IDs entfernen\n",
    "    df_ways = df_ways[df_ways['node_ids'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "    df_city_data_updated = pd.concat([df_nodes_final, df_ways], ignore_index=True)\n",
    "\n",
    "    return df_city_data_updated\n",
    "\n",
    "    # Löschen der Knoten, die durch anderen ersetzt wurde\n",
    "def remove_replaced_nodes(df_nodes, node_merge_dict):\n",
    "    replaced_node_ids = set(node_merge_dict.keys()) - set(node_merge_dict.values())\n",
    "    return df_nodes[~df_nodes['id'].isin(replaced_node_ids)]\n",
    "\n",
    "# Aktualisiere node_ids\n",
    "def update_node_ids_merged(node_ids, node_merge_dict):\n",
    "    if node_ids is not None and isinstance(node_ids, list):\n",
    "        updated_node_ids = [node_merge_dict.get(node_id, node_id) for node_id in node_ids]\n",
    "        # Entferne doppelte Knoten, falls sie durch das Zusammenführen entstanden sind\n",
    "        unique_node_ids = list(dict.fromkeys(updated_node_ids))\n",
    "        return unique_node_ids\n",
    "    return node_ids\n",
    "\n",
    "# Zusammenfügen der Knoten, die nah beieinander stehen\n",
    "def merge_within_distance(df_nodes, max_distance):\n",
    "    merged_nodes = []\n",
    "    node_merge_dict = {}\n",
    "    seen = set()\n",
    "\n",
    "    for i, node_1 in df_nodes.iterrows():\n",
    "        for j, node_2 in df_nodes.iterrows():\n",
    "            # Vergleich gleicher Knoten verhindern\n",
    "            if node_1['id'] == node_2['id'] or node_1['id'] in seen or node_2['id'] in seen:\n",
    "                continue\n",
    "\n",
    "            lon1, lat1 = node_1['longitude'], node_1['latitude']\n",
    "            lon2, lat2 = node_2['longitude'], node_2['latitude']\n",
    "\n",
    "            distance = haversine(lon1, lat1, lon2, lat2)\n",
    "\n",
    "            if distance < max_distance:\n",
    "                merged_node = {\n",
    "                    'id': node_1['id'],\n",
    "                    'longitude': (lon1 + lon2) / 2,\n",
    "                    'latitude': (lat1 + lat2) / 2\n",
    "                }\n",
    "                merged_nodes.append(merged_node)\n",
    "\n",
    "                # Knoten als gesehen markiert\n",
    "                seen.add(node_1['id'])\n",
    "                seen.add(node_2['id'])\n",
    "\n",
    "                node_merge_dict[node_2['id']] = node_1['id']\n",
    "\n",
    "    return merged_nodes, node_merge_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolierte Knoten entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_isolated_nodes(df):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for index, row in df[df['type'] == 'node'].iterrows():  \n",
    "        G.add_node(row['id'], pos=(row['longitude'], row['latitude']))\n",
    "\n",
    "    for index, way in df[df['type'] == 'way'].iterrows():\n",
    "        node_ids_list = way['node_ids']\n",
    "        if node_ids_list is not None:\n",
    "            filtered_node_ids_list = [node_id for node_id in node_ids_list if G.has_node(node_id)]\n",
    "            if len(filtered_node_ids_list) > 1:\n",
    "                for i in range(len(filtered_node_ids_list) - 1):\n",
    "                    G.add_edge(filtered_node_ids_list[i], filtered_node_ids_list[i + 1])\n",
    "\n",
    "    connected_nodes = set(G.nodes)\n",
    "    df = df[(df['type'] != 'node') | (df['id'].isin(connected_nodes))]\n",
    "    isolated_nodes = [node for node, degree in G.degree() if degree == 0]\n",
    "    df = df[~((df['type'] == 'node') & (df['id'].isin(isolated_nodes)))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alle Daten aus dem Datensatz auslesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>visible</th>\n",
       "      <th>ntags</th>\n",
       "      <th>tagkey</th>\n",
       "      <th>tagvalue</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>node_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>node</td>\n",
       "      <td>507975</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>TMC:cid_58:tabcd_1:Class</td>\n",
       "      <td>Point</td>\n",
       "      <td>9.012274</td>\n",
       "      <td>49.994112</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>node</td>\n",
       "      <td>507975</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>TMC:cid_58:tabcd_1:Direction</td>\n",
       "      <td>negative</td>\n",
       "      <td>9.012274</td>\n",
       "      <td>49.994112</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>node</td>\n",
       "      <td>507975</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>TMC:cid_58:tabcd_1:LCLversion</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.012274</td>\n",
       "      <td>49.994112</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>node</td>\n",
       "      <td>507975</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>TMC:cid_58:tabcd_1:LocationCode</td>\n",
       "      <td>10863</td>\n",
       "      <td>9.012274</td>\n",
       "      <td>49.994112</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>node</td>\n",
       "      <td>507975</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>TMC:cid_58:tabcd_1:NextLocationCode</td>\n",
       "      <td>59626</td>\n",
       "      <td>9.012274</td>\n",
       "      <td>49.994112</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14504017</th>\n",
       "      <td>way</td>\n",
       "      <td>1307299066</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>landuse</td>\n",
       "      <td>farmland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[12106567512, 12106567511, 12106567510, 121065...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14504018</th>\n",
       "      <td>way</td>\n",
       "      <td>1307299067</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>landuse</td>\n",
       "      <td>meadow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1258603417, 1258604236, 12106567525, 12106567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14504019</th>\n",
       "      <td>way</td>\n",
       "      <td>1307299068</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>landuse</td>\n",
       "      <td>meadow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[12106567540, 1258603672, 1258603933, 12106567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14504020</th>\n",
       "      <td>way</td>\n",
       "      <td>1307299069</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>landuse</td>\n",
       "      <td>meadow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1258603201, 12106567537, 12106567536, 1258604...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14504021</th>\n",
       "      <td>way</td>\n",
       "      <td>1307299070</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>landuse</td>\n",
       "      <td>forest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1258603933, 1258603672, 1258603201, 125860431...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14504022 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          type          id  visible  ntags  \\\n",
       "0         node      507975     True     10   \n",
       "1         node      507975     True     10   \n",
       "2         node      507975     True     10   \n",
       "3         node      507975     True     10   \n",
       "4         node      507975     True     10   \n",
       "...        ...         ...      ...    ...   \n",
       "14504017   way  1307299066     True      1   \n",
       "14504018   way  1307299067     True      1   \n",
       "14504019   way  1307299068     True      1   \n",
       "14504020   way  1307299069     True      1   \n",
       "14504021   way  1307299070     True      1   \n",
       "\n",
       "                                       tagkey  tagvalue  longitude   latitude  \\\n",
       "0                    TMC:cid_58:tabcd_1:Class     Point   9.012274  49.994112   \n",
       "1                TMC:cid_58:tabcd_1:Direction  negative   9.012274  49.994112   \n",
       "2               TMC:cid_58:tabcd_1:LCLversion      9.00   9.012274  49.994112   \n",
       "3             TMC:cid_58:tabcd_1:LocationCode     10863   9.012274  49.994112   \n",
       "4         TMC:cid_58:tabcd_1:NextLocationCode     59626   9.012274  49.994112   \n",
       "...                                       ...       ...        ...        ...   \n",
       "14504017                              landuse  farmland        NaN        NaN   \n",
       "14504018                              landuse    meadow        NaN        NaN   \n",
       "14504019                              landuse    meadow        NaN        NaN   \n",
       "14504020                              landuse    meadow        NaN        NaN   \n",
       "14504021                              landuse    forest        NaN        NaN   \n",
       "\n",
       "                                                   node_ids  \n",
       "0                                                      None  \n",
       "1                                                      None  \n",
       "2                                                      None  \n",
       "3                                                      None  \n",
       "4                                                      None  \n",
       "...                                                     ...  \n",
       "14504017  [12106567512, 12106567511, 12106567510, 121065...  \n",
       "14504018  [1258603417, 1258604236, 12106567525, 12106567...  \n",
       "14504019  [12106567540, 1258603672, 1258603933, 12106567...  \n",
       "14504020  [1258603201, 12106567537, 12106567536, 1258604...  \n",
       "14504021  [1258603933, 1258603672, 1258603201, 125860431...  \n",
       "\n",
       "[14504022 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OSMHandler(osm.SimpleHandler):\n",
    "    def __init__(self):\n",
    "        osm.SimpleHandler.__init__(self)\n",
    "        self.osm_data = []\n",
    "\n",
    "    def tag_inventory(self, elem, elem_type, lon=None, lat=None, node_ids=None):\n",
    "        if len(elem.tags) == 0:\n",
    "            # Für Knoten ohne Tags\n",
    "            self.osm_data.append([elem_type, \n",
    "                                  elem.id, \n",
    "                                  elem.visible,\n",
    "                                  0, \n",
    "                                  None, \n",
    "                                  None, \n",
    "                                  lon, \n",
    "                                  lat, \n",
    "                                  node_ids])\n",
    "        else:\n",
    "            for tag in elem.tags:\n",
    "                self.osm_data.append([elem_type, \n",
    "                                      elem.id,\n",
    "                                      elem.visible,\n",
    "                                      len(elem.tags),\n",
    "                                      tag.k, \n",
    "                                      tag.v, lon, lat, node_ids])\n",
    "\n",
    "    def node(self, n):\n",
    "        self.tag_inventory(n, \"node\", lon=n.location.lon, lat=n.location.lat)\n",
    "\n",
    "    def way(self, w):\n",
    "        node_ids = [n.ref for n in w.nodes]  \n",
    "        self.tag_inventory(w, \"way\", node_ids=node_ids)\n",
    "\n",
    "# Daten auslesen\n",
    "osmhandler = OSMHandler()\n",
    "osmhandler.apply_file(dataset_path)\n",
    "\n",
    "# DataFrame erstellen\n",
    "data_colnames = ['type', 'id', 'visible', 'ntags', 'tagkey', 'tagvalue', 'longitude', 'latitude', 'node_ids']\n",
    "df_osm = pd.DataFrame(osmhandler.osm_data, columns=data_colnames)\n",
    "df_osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensatz nach Wegen gefiltert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>visible</th>\n",
       "      <th>ntags</th>\n",
       "      <th>tagkey</th>\n",
       "      <th>tagvalue</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>node_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10879419</th>\n",
       "      <td>way</td>\n",
       "      <td>3665983</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>highway</td>\n",
       "      <td>motorway_link</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[18177874, 18177875, 18177876, 2145470970, 214...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879428</th>\n",
       "      <td>way</td>\n",
       "      <td>3665987</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>highway</td>\n",
       "      <td>primary_link</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[18177944, 8684650962, 8684650961, 18177945, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879441</th>\n",
       "      <td>way</td>\n",
       "      <td>3665989</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>highway</td>\n",
       "      <td>primary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[52002528, 7691431851, 3463913709, 298539137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879462</th>\n",
       "      <td>way</td>\n",
       "      <td>3665993</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>highway</td>\n",
       "      <td>secondary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[18178013, 610518435, 717818571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879482</th>\n",
       "      <td>way</td>\n",
       "      <td>3665996</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>highway</td>\n",
       "      <td>motorway_link</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[10799089, 10799091, 11579636997, 11579636996,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503812</th>\n",
       "      <td>way</td>\n",
       "      <td>1307134246</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>highway</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[12105226801, 2773668523]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503893</th>\n",
       "      <td>way</td>\n",
       "      <td>1307138944</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>highway</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[302490951, 9383332898, 4730339428, 4730339402]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503966</th>\n",
       "      <td>way</td>\n",
       "      <td>1307138950</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>highway</td>\n",
       "      <td>secondary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[11830891345, 11809434805]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503983</th>\n",
       "      <td>way</td>\n",
       "      <td>1307141259</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>highway</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[413711326, 503587053]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14504003</th>\n",
       "      <td>way</td>\n",
       "      <td>1307267510</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>highway</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[12106319358, 12106319359, 12106319360]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335843 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         type          id  visible  ntags   tagkey       tagvalue  longitude  \\\n",
       "10879419  way     3665983     True      6  highway  motorway_link        NaN   \n",
       "10879428  way     3665987     True     14  highway   primary_link        NaN   \n",
       "10879441  way     3665989     True     18  highway        primary        NaN   \n",
       "10879462  way     3665993     True     24  highway      secondary        NaN   \n",
       "10879482  way     3665996     True      9  highway  motorway_link        NaN   \n",
       "...       ...         ...      ...    ...      ...            ...        ...   \n",
       "14503812  way  1307134246     True      7  highway    residential        NaN   \n",
       "14503893  way  1307138944     True      4  highway    residential        NaN   \n",
       "14503966  way  1307138950     True      2  highway      secondary        NaN   \n",
       "14503983  way  1307141259     True      5  highway    residential        NaN   \n",
       "14504003  way  1307267510     True      2  highway        service        NaN   \n",
       "\n",
       "          latitude                                           node_ids  \n",
       "10879419       NaN  [18177874, 18177875, 18177876, 2145470970, 214...  \n",
       "10879428       NaN  [18177944, 8684650962, 8684650961, 18177945, 2...  \n",
       "10879441       NaN      [52002528, 7691431851, 3463913709, 298539137]  \n",
       "10879462       NaN                   [18178013, 610518435, 717818571]  \n",
       "10879482       NaN  [10799089, 10799091, 11579636997, 11579636996,...  \n",
       "...            ...                                                ...  \n",
       "14503812       NaN                          [12105226801, 2773668523]  \n",
       "14503893       NaN    [302490951, 9383332898, 4730339428, 4730339402]  \n",
       "14503966       NaN                         [11830891345, 11809434805]  \n",
       "14503983       NaN                             [413711326, 503587053]  \n",
       "14504003       NaN            [12106319358, 12106319359, 12106319360]  \n",
       "\n",
       "[335843 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ways_filter = df_osm[(df_osm['type'] == 'way') & (df_osm['tagkey'] == 'highway')]\n",
    "ways_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>visible</th>\n",
       "      <th>ntags</th>\n",
       "      <th>tagkey</th>\n",
       "      <th>tagvalue</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>node_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10879431</th>\n",
       "      <td>way</td>\n",
       "      <td>3665987</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[18177944, 8684650962, 8684650961, 18177945, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879444</th>\n",
       "      <td>way</td>\n",
       "      <td>3665989</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[52002528, 7691431851, 3463913709, 298539137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879467</th>\n",
       "      <td>way</td>\n",
       "      <td>3665993</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[18178013, 610518435, 717818571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879493</th>\n",
       "      <td>way</td>\n",
       "      <td>3665998</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[10799085, 760755019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879521</th>\n",
       "      <td>way</td>\n",
       "      <td>3981579</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[257170666, 584559, 2164889666, 1900187100, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503927</th>\n",
       "      <td>way</td>\n",
       "      <td>1307138947</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1511833077, 12105267729, 302491578]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503941</th>\n",
       "      <td>way</td>\n",
       "      <td>1307138948</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[12105267730, 302490651, 1511833090]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503955</th>\n",
       "      <td>way</td>\n",
       "      <td>1307138949</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[9707857044, 302490552]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503971</th>\n",
       "      <td>way</td>\n",
       "      <td>1307138951</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2237758066, 12105267734]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503984</th>\n",
       "      <td>way</td>\n",
       "      <td>1307141259</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>maxspeed</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[413711326, 503587053]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47145 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         type          id  visible  ntags    tagkey tagvalue  longitude  \\\n",
       "10879431  way     3665987     True     14  maxspeed      100        NaN   \n",
       "10879444  way     3665989     True     18  maxspeed       50        NaN   \n",
       "10879467  way     3665993     True     24  maxspeed       50        NaN   \n",
       "10879493  way     3665998     True     12  maxspeed       70        NaN   \n",
       "10879521  way     3981579     True     16  maxspeed       80        NaN   \n",
       "...       ...         ...      ...    ...       ...      ...        ...   \n",
       "14503927  way  1307138947     True     14  maxspeed       80        NaN   \n",
       "14503941  way  1307138948     True     14  maxspeed       80        NaN   \n",
       "14503955  way  1307138949     True     14  maxspeed       30        NaN   \n",
       "14503971  way  1307138951     True     15  maxspeed       60        NaN   \n",
       "14503984  way  1307141259     True      5  maxspeed       30        NaN   \n",
       "\n",
       "          latitude                                           node_ids  \n",
       "10879431       NaN  [18177944, 8684650962, 8684650961, 18177945, 2...  \n",
       "10879444       NaN      [52002528, 7691431851, 3463913709, 298539137]  \n",
       "10879467       NaN                   [18178013, 610518435, 717818571]  \n",
       "10879493       NaN                              [10799085, 760755019]  \n",
       "10879521       NaN  [257170666, 584559, 2164889666, 1900187100, 21...  \n",
       "...            ...                                                ...  \n",
       "14503927       NaN               [1511833077, 12105267729, 302491578]  \n",
       "14503941       NaN               [12105267730, 302490651, 1511833090]  \n",
       "14503955       NaN                            [9707857044, 302490552]  \n",
       "14503971       NaN                          [2237758066, 12105267734]  \n",
       "14503984       NaN                             [413711326, 503587053]  \n",
       "\n",
       "[47145 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ways_maxspeed = df_osm[(df_osm['type'] == 'way') & (df_osm['tagkey'] == 'maxspeed')]\n",
    "ways_maxspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API-Anfrage für die Längen- und Breitengrade der Städte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API-Anfrage um Bounding Box der Stadt zu bekommen\n",
    "def get_bounding_box(city_name):\n",
    "    url = f\"https://nominatim.openstreetmap.org/search?city={city_name}&format=json\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Bachelorproject/1.0\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        for result in results:\n",
    "            if result.get(\"osm_type\") in [\"node\", \"relation\"]:\n",
    "                if result.get(\"addresstype\") in [\"village\", \"town\", \"city\"] and 'boundingbox' in result:\n",
    "                    display_name = result.get(\"display_name\", \"\")\n",
    "                    if 'Bayern' in display_name:\n",
    "                        bbox = result['boundingbox']\n",
    "                        addresstype = result.get(\"addresstype\", \"\")\n",
    "                        return [float(coord) for coord in bbox], addresstype  \n",
    "    raise ValueError(\"Bounding Box konnte nicht abgerufen werden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensatz nach Städten filtern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Würzburger Straße 45...\n",
      "Processing City filter...\n",
      "Processing Intersection filter...\n",
      "Processing 2 degree removal...\n",
      "Datei erfolgreich gespeichert: City_data\\university\\Würzburger Straße 45.osm\n",
      "Processing Würzburger Straße 45...\n",
      "Processing City filter...\n",
      "Processing Intersection filter...\n",
      "Processing 2 degree removal...\n",
      "Datei erfolgreich gespeichert: City_data\\university\\Würzburger Straße 45.osm\n",
      "Datei erfolgreich gespeichert: City_data\\university\\Würzburger Straße 45.osm\n"
     ]
    }
   ],
   "source": [
    "def process_cities(cities, ways_filter):\n",
    "    for city in cities:\n",
    "        try:\n",
    "            for i in range(2):\n",
    "                print(f\"Processing {city}...\")\n",
    "                bbox, addresstype = get_bounding_box(city)\n",
    "                south, north, west, east = bbox\n",
    "\n",
    "                df_filtered_nodes = df_osm[\n",
    "                    ((df_osm['latitude'] >= south) & (df_osm['latitude'] <= north)) &\n",
    "                    ((df_osm['longitude'] >= west) & (df_osm['longitude'] <= east))    \n",
    "                ]\n",
    "\n",
    "                print(\"Processing City filter...\")\n",
    "                ways = ways_filter[ways_filter['node_ids'].apply(lambda node_ids: \n",
    "                    isinstance(node_ids, list) and any(node in df_filtered_nodes['id'].values for node in node_ids))]\n",
    "            \n",
    "                road_lengths = []\n",
    "                for index, way_row in ways.iterrows():\n",
    "                    length = calculate_full_road_length(way_row, df_filtered_nodes)\n",
    "                    if length is not None:\n",
    "                        road_lengths.append({'id': way_row['id'], 'length': length})\n",
    "\n",
    "                df_road_length = pd.DataFrame(road_lengths)\n",
    "                ways = ways.merge(df_road_length, on='id', how='left')\n",
    "\n",
    "                df_filtered = pd.concat([df_filtered_nodes, ways])\n",
    "                df_filtered = df_filtered.fillna('')\n",
    "                print(\"Processing Intersection filter...\")\n",
    "                df_filtered = filter_highway_nodes(df_filtered)\n",
    "\n",
    "                print(\"Processing 2 degree removal...\")\n",
    "                df_filtered = remove_degree_2_nodes_from_file(df_filtered, ways_filter)\n",
    "                df_filtered = df_filtered.fillna('')\n",
    "            \n",
    "                save_to_xml(df_filtered, city, addresstype)\n",
    "            \n",
    "            print(\"Processing merging...\")\n",
    "            df_filtered = process_merging(df_filtered)\n",
    "            \n",
    "            print(\"Processing Isolation filter...\")\n",
    "            df_filtered = remove_isolated_nodes(df_filtered)\n",
    "\n",
    "            save_to_xml(df_filtered, city, addresstype)\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Fehler beim Verarbeiten der Stadt {city}: {e}\")\n",
    "\n",
    "process_cities(cities, ways_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straßennetzwerke und ihre Muster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Straßennetzwerke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samu2\\AppData\\Local\\Temp\\ipykernel_6404\\2788426504.py:37: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap('tab20', len(highway_types))\n"
     ]
    }
   ],
   "source": [
    "city_folder = \"City_data\"\n",
    "files = []\n",
    "for subfolder in ['village', 'town', 'city']:\n",
    "    full_path = os.path.join(city_folder, subfolder)\n",
    "    files.extend([os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")])\n",
    "\n",
    "output_folder = \"Street Network\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    city_name = os.path.splitext(os.path.basename(file))[0]\n",
    "    df_city_data = load_from_all_xml(file)\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Knoten hinzufügen\n",
    "    for index, row in df_city_data[df_city_data['type'] == 'node'].iterrows():\n",
    "        G.add_node(row['id'], pos=(row['longitude'], row['latitude']))\n",
    "\n",
    "    # Kanten hinzufügen\n",
    "    for index, way in df_city_data[df_city_data['type'] == 'way'].iterrows():\n",
    "        node_ids_list = way['node_ids']\n",
    "        if node_ids_list is not None:\n",
    "            filtered_node_ids_list = [node_id for node_id in node_ids_list if G.has_node(node_id)]\n",
    "            if len(filtered_node_ids_list) > 1:\n",
    "                highway_type = way['tagvalue']\n",
    "                for i in range(len(filtered_node_ids_list) - 1):\n",
    "                    G.add_edge(\n",
    "                        filtered_node_ids_list[i], filtered_node_ids_list[i + 1],\n",
    "                        street_name=highway_type,\n",
    "                        highway_type=highway_type\n",
    "                    )\n",
    "\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "\n",
    "    highway_types = set(d['highway_type'] for u, v, d in G.edges(data=True))\n",
    "    colors = plt.cm.get_cmap('tab20', len(highway_types))\n",
    "    highway_color_map = {highway_type: colors(i) for i, highway_type in enumerate(highway_types)}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 16))\n",
    "\n",
    "    for highway_type, color in highway_color_map.items():\n",
    "        edges_by_type = [(u, v) for u, v, d in G.edges(data=True) if d.get('highway_type') == highway_type]\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=edges_by_type, edge_color=[color]*len(edges_by_type), width=1.5, ax=ax)\n",
    "\n",
    "    node_degrees = dict(G.degree())\n",
    "    node_color = ['red' if node_degrees[node] >= 3 else 'blue' for node in G.nodes()]\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=1, node_color=node_color, ax=ax)\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], color=highway_color_map[highway_type], lw=2, label=highway_type)\n",
    "                       for highway_type in highway_color_map]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "    ax.set_aspect(1.0 / np.cos(50 * np.pi / 180))\n",
    "\n",
    "    # Netzwerk speichern\n",
    "    output_file = os.path.join(output_folder, f\"{city_name}.png\")\n",
    "    plt.savefig(output_file, bbox_inches='tight', pad_inches=0, dpi=200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straßendiversität"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der Straßentypen anhand der Länge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_highway_types():\n",
    "    city_folder = \"City_data\"\n",
    "    highway_lengths = defaultdict(float)\n",
    "\n",
    "    for root, dirs, files in os.walk(city_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".osm\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                df = load_from_all_xml(file_path)\n",
    "\n",
    "                highway_df = df[(df['type'] == 'way') & (df['tagkey'] == 'highway') & (df['length'].notna())]\n",
    "                \n",
    "                # Without track\n",
    "                #highway_df = highway_df[highway_df['tagvalue'] != 'track']\n",
    "\n",
    "                length_sums = highway_df.groupby('tagvalue')['length'].sum()\n",
    "\n",
    "                for highway_type, total_length in length_sums.items():\n",
    "                    highway_lengths[highway_type] += total_length\n",
    "\n",
    "    highway_lengths_df = pd.DataFrame.from_dict(highway_lengths, orient='index', columns=['total_length']).reset_index()\n",
    "    highway_lengths_df.rename(columns={'index': 'highway_type'}, inplace=True)\n",
    "    highway_lengths_df.sort_values(by='total_length', ascending=False, inplace=True)\n",
    "\n",
    "    return highway_lengths_df\n",
    "\n",
    "highway_lengths_df = sum_highway_types()\n",
    "output_folder = \"Street diversity\"\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='total_length', y='highway_type', data=highway_lengths_df)\n",
    "plt.title('Gesamtstraßenlänge pro Straßenart in allen Dateien')\n",
    "plt.xlabel('Gesamtstraßenlänge (m)')\n",
    "plt.ylabel('Straßenart')\n",
    "plt.savefig(os.path.join(output_folder, \"Total_street_length_of_each_type.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der Straßentypen anhand der Länge pro Stadt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage_highway_lengths_with_limit():\n",
    "    city_folder = \"City_data\"\n",
    "    result = []\n",
    "\n",
    "    for subfolder in ['village', 'town', 'city']:\n",
    "        full_path = os.path.join(city_folder, subfolder)\n",
    "        files = [os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")]\n",
    "\n",
    "        for file_path in files:\n",
    "            df = load_from_all_xml(file_path)\n",
    "\n",
    "            highway_df = df[(df['type'] == 'way') & (df['tagkey'] == 'highway')]\n",
    "\n",
    "            # Without track\n",
    "            #highway_df = highway_df[highway_df['tagvalue'] != 'track']\n",
    "\n",
    "            total_length = highway_df['length'].sum()\n",
    "            \n",
    "            if total_length > 0:\n",
    "                length_by_type = highway_df.groupby('tagvalue')['length'].sum()\n",
    "                length_by_type_sorted = length_by_type.sort_values(ascending=False).head(7)\n",
    "                for highway_type, length in length_by_type_sorted.items():\n",
    "                    percentage = (length / total_length) * 100\n",
    "                    result.append({\n",
    "                        'city': os.path.basename(file_path).split('.')[0],\n",
    "                        'highway_type': highway_type,\n",
    "                        'percentage': percentage\n",
    "                    })\n",
    "\n",
    "    percentage_lengths_df = pd.DataFrame(result)\n",
    "    return percentage_lengths_df\n",
    "\n",
    "percentage_lengths_df = calculate_percentage_highway_lengths_with_limit()\n",
    "output_folder = \"Street diversity\"\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(\n",
    "    x='city', y='percentage', hue='highway_type',\n",
    "    data=percentage_lengths_df, palette='muted'\n",
    ")\n",
    "plt.title('Prozentualer Anteil der Straßentypen zur Gesamtlänge in jeder Stadt')\n",
    "plt.xlabel('Stadt')\n",
    "plt.ylabel('Prozentualer Anteil der Gesamtlänge (%)')\n",
    "plt.legend(title='Straßentyp')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Street_length_of_type_to_respective_city.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage_highway_lengths():\n",
    "    city_folder = \"City_data\"\n",
    "    result = []\n",
    "\n",
    "    for subfolder in ['village', 'town', 'city']:\n",
    "        full_path = os.path.join(city_folder, subfolder)\n",
    "        files = [os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")]\n",
    "\n",
    "        for file_path in files:\n",
    "            df = load_from_all_xml(file_path)\n",
    "\n",
    "            highway_df = df[(df['type'] == 'way') & (df['tagkey'] == 'highway')]\n",
    "\n",
    "            # Without track\n",
    "            #highway_df = highway_df[highway_df['tagvalue'] != 'track']\n",
    "\n",
    "            total_length = highway_df['length'].sum()\n",
    "            \n",
    "            if total_length > 0:\n",
    "                length_by_type = highway_df.groupby('tagvalue')['length'].sum()\n",
    "                length_by_type_sorted = length_by_type.sort_values(ascending=False)\n",
    "                for highway_type, length in length_by_type_sorted.items():\n",
    "                    percentage = (length / total_length) * 100\n",
    "                    result.append({\n",
    "                        'city': os.path.basename(file_path).split('.')[0],\n",
    "                        'highway_type': highway_type,\n",
    "                        'percentage': percentage\n",
    "                    })\n",
    "\n",
    "    percentage_lengths_df = pd.DataFrame(result)\n",
    "    return percentage_lengths_df\n",
    "\n",
    "percentage_lengths_df = calculate_percentage_highway_lengths()\n",
    "output_folder = \"Street diversity\"\n",
    "\n",
    "for city in percentage_lengths_df['city'].unique():\n",
    "    city_df = percentage_lengths_df[percentage_lengths_df['city'] == city]\n",
    "\n",
    "    city_output_folder = os.path.join(output_folder, city)\n",
    "    os.makedirs(city_output_folder, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='highway_type', y='percentage', data=city_df, palette='muted')\n",
    "    plt.title(f'Prozentualer Anteil der Straßentypen in {city}')\n",
    "    plt.xlabel('Straßentyp')\n",
    "    plt.ylabel('Prozentualer Anteil der Gesamtlänge (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(os.path.join(city_output_folder, f\"Street_length_percentage_{city}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shannon-Wiener-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_wiener_index(probabilities):\n",
    "    return -np.sum(probabilities * np.log(probabilities))\n",
    "\n",
    "def calculate_shannon_wiener_index():\n",
    "    city_folder = \"City_data\"\n",
    "    result = []\n",
    "\n",
    "    for subfolder in ['village', 'town', 'city']:\n",
    "        full_path = os.path.join(city_folder, subfolder)\n",
    "        files = [os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")]\n",
    "\n",
    "        for file_path in files:\n",
    "            df = load_from_all_xml(file_path)\n",
    "\n",
    "            highway_df = df[(df['type'] == 'way') & (df['tagkey'] == 'highway')]\n",
    "\n",
    "            total_length = highway_df['length'].sum()\n",
    "\n",
    "            if total_length > 0:\n",
    "                length_by_type = highway_df.groupby('tagvalue')['length'].sum()\n",
    "                length_by_type_sorted = length_by_type / total_length  \n",
    "                sw_index = shannon_wiener_index(length_by_type_sorted)\n",
    "                result.append({\n",
    "                    'city': os.path.basename(file_path).split('.')[0],\n",
    "                    'shannon_wiener_index': sw_index\n",
    "                })\n",
    "\n",
    "    sw_index_df = pd.DataFrame(result)\n",
    "    return sw_index_df\n",
    "\n",
    "sw_index_df = calculate_shannon_wiener_index()\n",
    "output_folder = \"Street diversity\"\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='city', y='shannon_wiener_index', data=sw_index_df, palette='viridis')\n",
    "plt.title('Shannon-Wiener-Index der Straßenvielfalt in verschiedenen Städten')\n",
    "plt.xlabel('Stadt')\n",
    "plt.ylabel('Shannon-Wiener-Index')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Shannon_Wiener_Index_Cities.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df, city):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for _, row in df[df['type'] == 'node'].iterrows():  \n",
    "        G.add_node(row['id'], pos=(row['longitude'], row['latitude']))\n",
    "\n",
    "    for _, way in df[df['type'] == 'way'].iterrows():\n",
    "        highway_type = way['tagvalue']\n",
    "        if highway_type == 'track':\n",
    "            continue\n",
    "        \n",
    "        node_ids_list = way['node_ids']\n",
    "        if node_ids_list is not None:\n",
    "            filtered_node_ids_list = [node_id for node_id in node_ids_list if G.has_node(node_id)]\n",
    "            if len(filtered_node_ids_list) > 1:\n",
    "                for i in range(len(filtered_node_ids_list) - 1):\n",
    "                    G.add_edge(filtered_node_ids_list[i], filtered_node_ids_list[i + 1], highway_type=highway_type)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def is_connected_to_non_track_way(G, node_id):\n",
    "    for neighbor in G.neighbors(node_id):\n",
    "        edge_data = G.get_edge_data(node_id, neighbor)\n",
    "        if edge_data['highway_type'] != 'track':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def select_random_node_pairs(df_nodes, G, num_pairs=1, min_distance=1000):\n",
    "    random_pairs = []\n",
    "    nodes = df_nodes['id'].values\n",
    "\n",
    "    while len(random_pairs) < num_pairs:\n",
    "        start_node, end_node = random.sample(list(nodes), 2)\n",
    "        \n",
    "        if is_connected_to_non_track_way(G, start_node) and is_connected_to_non_track_way(G, end_node):\n",
    "            distance = haversine(\n",
    "                df_nodes[df_nodes['id'] == start_node]['longitude'].values[0], \n",
    "                df_nodes[df_nodes['id'] == start_node]['latitude'].values[0],\n",
    "                df_nodes[df_nodes['id'] == end_node]['longitude'].values[0],\n",
    "                df_nodes[df_nodes['id'] == end_node]['latitude'].values[0]\n",
    "            )\n",
    "            if distance >= min_distance:\n",
    "                random_pairs.append((start_node, end_node))\n",
    "\n",
    "    return random_pairs\n",
    "\n",
    "def run_dijkstra_and_track_types(G, start_node, end_node):\n",
    "    if start_node not in G or end_node not in G:\n",
    "        print(f\"Knoten {start_node} oder {end_node} nicht im Graphen vorhanden.\")\n",
    "        return None, 0  \n",
    "\n",
    "    try:\n",
    "        shortest_path = nx.dijkstra_path(G, source=start_node, target=end_node, weight='weight')\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None, 0  \n",
    "\n",
    "    total_length = 0  \n",
    "    type_lengths = {}  \n",
    "\n",
    "    for i in range(len(shortest_path) - 1):\n",
    "        node1, node2 = shortest_path[i], shortest_path[i + 1]\n",
    "        edge_data = G.get_edge_data(node1, node2)\n",
    "        highway_type = edge_data['highway_type']\n",
    "        \n",
    "        lon1, lat1 = G.nodes[node1]['pos']\n",
    "        lon2, lat2 = G.nodes[node2]['pos']\n",
    "        length = haversine(lon1, lat1, lon2, lat2)\n",
    "        total_length += length\n",
    "\n",
    "        type_lengths[highway_type] = type_lengths.get(highway_type, 0) + length\n",
    "    \n",
    "    return type_lengths, total_length\n",
    "\n",
    "def plot_traffic_efficiency(results_df, output_folder):\n",
    "    dijkstra_folder = os.path.join(output_folder, 'Dijkstra')\n",
    "    os.makedirs(dijkstra_folder, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='highway_type', y='percentage', hue='city', data=results_df, palette='muted', errorbar=None)\n",
    "    plt.title('Verkehrseffizienz: Prozentualer Anteil der Straßentypen zur Gesamtlänge')\n",
    "    plt.xlabel('Straßentyp')\n",
    "    plt.ylabel('Prozentualer Anteil (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(dijkstra_folder, 'Dijkstra_Analysis_All.png'))\n",
    "    plt.close()\n",
    "\n",
    "    #filtered_df = results_df[results_df['highway_type'] != 'track']\n",
    "\n",
    "    #plt.figure(figsize=(10, 6))\n",
    "    #sns.barplot(x='highway_type', y='percentage', hue='city', data=filtered_df, palette='muted', errorbar=None)\n",
    "    #plt.title('Verkehrseffizienz (ohne track): Prozentualer Anteil der Straßentypen zur Gesamtlänge')\n",
    "    #plt.xlabel('Straßentyp')\n",
    "    #plt.ylabel('Prozentualer Anteil (%)')\n",
    "    #plt.xticks(rotation=45)\n",
    "    #plt.tight_layout()\n",
    "    #plt.savefig(os.path.join(dijkstra_folder, 'Dijkstra_Analysis_Without_Track.png'))\n",
    "    #plt.close()\n",
    "\n",
    "def perform_dijkstra_analysis():\n",
    "    city_folder = \"City_data\"\n",
    "    output_folder = \"Street diversity\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    distance_mapping = {\n",
    "        \"village\": 800,\n",
    "        \"town\": 1000,\n",
    "        \"city\": 2000\n",
    "    }\n",
    "\n",
    "    all_results = []  \n",
    "\n",
    "    for subfolder in ['village', 'town', 'city']:\n",
    "        full_path = os.path.join(city_folder, subfolder)\n",
    "        subfolder_files = [os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")]\n",
    "\n",
    "        for file in subfolder_files:\n",
    "            city_name = os.path.splitext(os.path.basename(file))[0]\n",
    "            df = load_from_all_xml(file)\n",
    "            G = create_graph(df, city_name)\n",
    "            df_nodes = df[df['type'] == 'node']\n",
    "\n",
    "            min_distance = distance_mapping[subfolder]\n",
    "\n",
    "            for iteration in range(500): \n",
    "                print(f\"Iteration {iteration + 1}/500 für Stadt: {city_name}\")\n",
    "                node_pairs = select_random_node_pairs(df_nodes, G, num_pairs=10, min_distance=min_distance)\n",
    "\n",
    "                total_types_length = {}\n",
    "                total_length = 0\n",
    "\n",
    "                for start_node, end_node in node_pairs:\n",
    "                    type_lengths, path_length = run_dijkstra_and_track_types(G, start_node, end_node)\n",
    "\n",
    "                    while type_lengths is None: \n",
    "                        start_node, end_node = random.choice(node_pairs)\n",
    "                        type_lengths, path_length = run_dijkstra_and_track_types(G, start_node, end_node)\n",
    "\n",
    "                    total_length += path_length\n",
    "                    for highway_type, length in type_lengths.items():\n",
    "                        total_types_length[highway_type] = total_types_length.get(highway_type, 0) + length\n",
    "\n",
    "                results = []\n",
    "                for highway_type, length in total_types_length.items():\n",
    "                    percentage = (length / total_length) * 100\n",
    "                    results.append({'city': city_name, 'highway_type': highway_type, 'percentage': percentage})\n",
    "\n",
    "                all_results.extend(results)\n",
    "\n",
    "            #print(f\"Alle Iterationen für {city_name} abgeschlossen. Warte 10 Sekunden...\")\n",
    "            #time.sleep(10)\n",
    "\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    plot_traffic_efficiency(results_df, output_folder)\n",
    "\n",
    "perform_dijkstra_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straßenlängen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplott der Straßenlängen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def street_length_comparison():\n",
    "    city_folder = \"City_data\"\n",
    "    files = []\n",
    "    \n",
    "    for subfolder in ['village', 'town', 'city']:\n",
    "        full_path = os.path.join(city_folder, subfolder)\n",
    "        files.extend([os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")])\n",
    "\n",
    "    all_lengths = []\n",
    "\n",
    "    for file in files:\n",
    "        df = load_from_all_xml(file)\n",
    "\n",
    "        # Filtere Wege, um 'track' auszuschließen\n",
    "        df_ways = df[(df['type'] == 'way') & (df['tagvalue'] != 'track')]\n",
    "\n",
    "        # Finde alle Knoten, die nur mit 'track'-Wege verbunden sind\n",
    "        track_nodes = set()\n",
    "        for _, way in df[df['tagvalue'] == 'track'].iterrows():\n",
    "            if way['node_ids'] is not None:\n",
    "                track_nodes.update(way['node_ids'])\n",
    "\n",
    "        # Prüfe, ob diese Knoten auch in anderen Straßen vorkommen\n",
    "        connected_nodes = set()\n",
    "        for _, way in df_ways.iterrows():\n",
    "            if way['node_ids'] is not None:\n",
    "                connected_nodes.update(way['node_ids'])\n",
    "\n",
    "        # Behalte nur Knoten, die nicht ausschließlich in 'track' verwendet wurden\n",
    "        valid_nodes = connected_nodes - track_nodes\n",
    "\n",
    "        # Filtere Wege weiter, um nur Straßen mit gültigen Knoten zu behalten\n",
    "        df_filtered = df_ways[df_ways['node_ids'].apply(lambda nodes: any(node in valid_nodes for node in nodes))]\n",
    "        \n",
    "        # Nur Straßen mit Längen auswählen\n",
    "        df_filtered = df_filtered[df_filtered['length'].notna()]\n",
    "        \n",
    "        city_name = os.path.basename(file).replace(\".osm\", \"\")\n",
    "        df_filtered['city'] = city_name\n",
    "        all_lengths.append(df_filtered[['length', 'city']])\n",
    "\n",
    "    df_all_lengths = pd.concat(all_lengths, ignore_index=True)\n",
    "\n",
    "    output_folder = \"Street length of various places\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    sns.boxplot(data=df_all_lengths, x='city', y='length')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Straßenlängen pro Stadt\")\n",
    "    plt.xlabel(\"Stadt\")\n",
    "    plt.ylabel(\"Länge (m)\")\n",
    "    #plt.ylim(0, 2000)\n",
    "    plt.savefig(os.path.join(output_folder, \"Street_length_comparison.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramm zu den Straßenlängen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def street_length_per_city():\n",
    "    city_folder = \"City_data\"\n",
    "    files = []\n",
    "    for subfolder in ['village', 'town', 'city']:\n",
    "        full_path = os.path.join(city_folder, subfolder)\n",
    "        files.extend([os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")])\n",
    "\n",
    "    for file in files:\n",
    "        city_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        df = load_from_all_xml(file)\n",
    "\n",
    "        # Filtere alle \"track\"-Wege heraus\n",
    "        df_filtered_ways = df[(df['type'] == 'way') & df['length'].notna() & (df['tagvalue'] != 'track')]\n",
    "\n",
    "        # Finde alle Knoten, die in nicht-track-Wegen vorkommen\n",
    "        valid_nodes = set()\n",
    "        for node_list in df_filtered_ways['node_ids'].dropna():\n",
    "            valid_nodes.update(node_list)\n",
    "\n",
    "        # Entferne Wege, die nur aus Knoten bestehen, die an \"track\"-Wege angeschlossen sind\n",
    "        df_filtered = df_filtered_ways[df_filtered_ways['node_ids'].apply(lambda nodes: any(n in valid_nodes for n in nodes))]\n",
    "\n",
    "        # Erstelle das Ausgabe-Ordner\n",
    "        output_folder = \"Street length of various places\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        city_output_folder = os.path.join(output_folder, city_name)\n",
    "        os.makedirs(city_output_folder, exist_ok=True)\n",
    "\n",
    "        # Erstelle Histogramm der Straßenlängen\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df_filtered['length'], bins=30, kde=True)\n",
    "        plt.xscale(\"log\")\n",
    "        plt.title(f\"Straßenlängen in {city_name}\")\n",
    "        plt.xlabel(\"Straßenlänge (log)\")\n",
    "        plt.ylabel(\"Anzahl der Straßen\")\n",
    "        plt.savefig(os.path.join(city_output_folder, f\"Street_length_{city_name}.png\"))\n",
    "        plt.close()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_length_comparison()\n",
    "street_length_per_city()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netzwerkdichte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramm für Knotengrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding-Boxen für die Städte\n",
    "bounding_boxes = {\n",
    "    \"Mannheim\": [(49.4797439235994, 8.459271481182554), (49.49572620679408, 8.472869522710699)],\n",
    "    \"Karlsruhe\": [(49.00567848315833, 8.388093017247659), (49.02507245712048, 8.418621377202044)],\n",
    "    \"Würzburg\": [(49.79053751531416, 9.92684010036795), (49.79589106529845, 9.935191771430993)]\n",
    "}\n",
    "\n",
    "city_folder = \"City_data\"\n",
    "files = []\n",
    "for subfolder in ['city']:\n",
    "    full_path = os.path.join(city_folder, subfolder)\n",
    "    files.extend([os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")])\n",
    "\n",
    "columns = 3\n",
    "rows = (len(files) + columns - 1) // columns  \n",
    "fig, axes = plt.subplots(rows, columns, figsize=(15, 5 * rows), squeeze=False)\n",
    "\n",
    "for idx, file in enumerate(files):\n",
    "    city_name = os.path.splitext(os.path.basename(file))[0]\n",
    "    city_data = load_from_all_xml(file)\n",
    "\n",
    "    if city_name not in bounding_boxes:\n",
    "        print(f\"Keine Bounding-Box für {city_name}, überspringe...\")\n",
    "        continue\n",
    "\n",
    "    (lat_min, lon_min), (lat_max, lon_max) = bounding_boxes[city_name]\n",
    "\n",
    "    # Netzwerkgraph für diese Stadt erstellen\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Knoten hinzufügen (nur wenn sie innerhalb der Bounding-Box liegen)\n",
    "    filtered_nodes = city_data[\n",
    "        (city_data['type'] == 'node') &\n",
    "        (city_data['latitude'].between(lat_min, lat_max)) &\n",
    "        (city_data['longitude'].between(lon_min, lon_max))\n",
    "    ]\n",
    "    node_ids_in_bbox = set(filtered_nodes['id'])\n",
    "\n",
    "    for _, row in city_data[city_data['type'] == 'way'].iterrows():\n",
    "        node_ids = row['node_ids']\n",
    "        if node_ids is not None:\n",
    "            # Nur Kanten hinzufügen, wenn beide Knoten innerhalb der Bounding-Box sind\n",
    "            valid_node_ids = [node_id for node_id in node_ids if node_id in node_ids_in_bbox]\n",
    "            for i in range(len(valid_node_ids) - 1):\n",
    "                G.add_edge(valid_node_ids[i], valid_node_ids[i + 1])\n",
    "\n",
    "    # Knotengrade berechnen (nur für Knoten in der Bounding-Box)\n",
    "    node_degrees = dict(G.degree())\n",
    "    \n",
    "    # Knoten mit Grad > 0 filtern\n",
    "    filtered_nodes['degree'] = filtered_nodes['id'].map(node_degrees).fillna(0).astype(int)\n",
    "    filtered_nodes = filtered_nodes[filtered_nodes['degree'] > 0]\n",
    "\n",
    "    # Knotengrade auf maximal 6 beschränken\n",
    "    city_node_degrees = filtered_nodes[filtered_nodes['degree'] <= 6]['degree']\n",
    "\n",
    "    # Position im Gitterlayout berechnen\n",
    "    row, col = divmod(idx, columns)\n",
    "    ax = axes[row][col]\n",
    "\n",
    "    bins = np.arange(1, 7) - 0.5\n",
    "    \n",
    "    sns.histplot(city_node_degrees, bins=bins, kde=True, ax=ax)  \n",
    "    ax.set_title(f\"Knotengrade in {city_name} (Gefiltert)\")\n",
    "    ax.set_xlabel(\"Knotengrad\")\n",
    "    ax.set_ylabel(\"Anzahl der Knoten\")\n",
    "    ax.set_xticks(range(1, 7))\n",
    "\n",
    "for idx in range(len(files), rows * columns):\n",
    "    row, col = divmod(idx, columns)\n",
    "    axes[row][col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-basierte Analyse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_grid_density(df_nodes, df_ways, grid_size=200):\n",
    "    earth_radius = 6371000\n",
    "    df_nodes['x'] = np.radians(df_nodes['longitude']) * np.cos(np.radians(df_nodes['latitude'])) * earth_radius\n",
    "    df_nodes['y'] = np.radians(df_nodes['latitude']) * earth_radius\n",
    "\n",
    "    df_nodes['grid_x'] = (df_nodes['x'] // grid_size).astype(int)\n",
    "    df_nodes['grid_y'] = (df_nodes['y'] // grid_size).astype(int)\n",
    "\n",
    "    # Entferne track-Wege\n",
    "    df_ways = df_ways[df_ways['tagvalue'] != 'track']\n",
    "\n",
    "    # Finde Knoten, die nur an track-Wege angeschlossen sind\n",
    "    all_nodes = set(df_nodes['id'])\n",
    "    connected_nodes = set()\n",
    "    \n",
    "    for _, row in df_ways.iterrows():\n",
    "        if row['node_ids'] is not None:\n",
    "            connected_nodes.update(row['node_ids'])\n",
    "\n",
    "    isolated_nodes = all_nodes - connected_nodes\n",
    "    df_nodes = df_nodes[~df_nodes['id'].isin(isolated_nodes)]\n",
    "\n",
    "    edges = []\n",
    "    for _, row in df_ways.iterrows():\n",
    "        node_ids = row['node_ids']\n",
    "        if node_ids is not None:\n",
    "            for i in range(len(node_ids) - 1):\n",
    "                edges.append((node_ids[i], node_ids[i + 1]))\n",
    "\n",
    "    edges_df = pd.DataFrame(edges, columns=['node1', 'node2'])\n",
    "    edges_df = edges_df.merge(df_nodes[['id', 'grid_x', 'grid_y']], left_on='node1', right_on='id', how='left').rename(columns={'grid_x': 'grid_x1', 'grid_y': 'grid_y1'}).drop(columns=['id'])\n",
    "    edges_df = edges_df.merge(df_nodes[['id', 'grid_x', 'grid_y']], left_on='node2', right_on='id', how='left').rename(columns={'grid_x': 'grid_x2', 'grid_y': 'grid_y2'}).drop(columns=['id'])\n",
    "\n",
    "    edges_df = edges_df[(edges_df['grid_x1'] == edges_df['grid_x2']) & (edges_df['grid_y1'] == edges_df['grid_y2'])]\n",
    "\n",
    "    edges_df['grid_x'] = edges_df['grid_x1']\n",
    "    edges_df['grid_y'] = edges_df['grid_y1']\n",
    "\n",
    "    edge_density = edges_df.groupby(['grid_x', 'grid_y']).size().reset_index(name='edge_count')\n",
    "    return edge_density\n",
    "\n",
    "city_folder = \"City_data\"\n",
    "files = []\n",
    "for subfolder in ['village', 'town', 'city']:\n",
    "    full_path = os.path.join(city_folder, subfolder)\n",
    "    files.extend([os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")])\n",
    "all_densities = []\n",
    "\n",
    "for file in files:\n",
    "    city_name = os.path.splitext(os.path.basename(file))[0]\n",
    "    df = load_from_all_xml(file)\n",
    "    \n",
    "    df_nodes = df[df['type'] == 'node']\n",
    "    df_ways = df[df['type'] == 'way']\n",
    "    \n",
    "    # Berechne Knotendichte\n",
    "    grid_density = calculate_grid_density(df_nodes, df_ways)\n",
    "    grid_density['city_name'] = city_name\n",
    "    all_densities.append(grid_density)\n",
    "\n",
    "output_folder = \"Density of various places\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Kombiniere die Knotendichten aller Städte\n",
    "df_all_densities = pd.concat(all_densities, ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_all_densities, x='city_name', y='edge_count')\n",
    "plt.title(\"Vergleich der Netzwerkdichte im 200m-Gitternetz\")\n",
    "plt.xlabel(\"Stadt\")\n",
    "plt.ylim(0, 25)\n",
    "plt.ylabel(\"Netzwerkdichte (Anzahl Kanten pro Gitterzelle)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Network_density_comparison_200m_Grid.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_grid_density(df_nodes, df_ways, grid_size=100):\n",
    "    earth_radius = 6371000\n",
    "\n",
    "    # Filtere alle track-Wege heraus\n",
    "    df_ways = df_ways[df_ways['tagvalue'] != 'track']\n",
    "\n",
    "    # Entferne Knoten, die nur an track-Wege angeschlossen sind\n",
    "    used_nodes = set(df_ways['node_ids'].explode().unique())\n",
    "    df_nodes = df_nodes[df_nodes['id'].isin(used_nodes)]\n",
    "\n",
    "    df_nodes['x'] = np.radians(df_nodes['longitude']) * np.cos(np.radians(df_nodes['latitude'])) * earth_radius\n",
    "    df_nodes['y'] = np.radians(df_nodes['latitude']) * earth_radius\n",
    "\n",
    "    df_nodes['grid_x'] = (df_nodes['x'] // grid_size).astype(int)\n",
    "    df_nodes['grid_y'] = (df_nodes['y'] // grid_size).astype(int)\n",
    "\n",
    "    edges = []\n",
    "    for _, row in df_ways.iterrows():\n",
    "        node_ids = row['node_ids']\n",
    "        if node_ids is not None:\n",
    "            for i in range(len(node_ids) - 1):\n",
    "                edges.append((node_ids[i], node_ids[i + 1]))\n",
    "\n",
    "    edges_df = pd.DataFrame(edges, columns=['node1', 'node2'])\n",
    "    edges_df = edges_df.merge(df_nodes[['id', 'grid_x', 'grid_y']], left_on='node1', right_on='id', how='left').rename(columns={'grid_x': 'grid_x1', 'grid_y': 'grid_y1'}).drop(columns=['id'])\n",
    "    edges_df = edges_df.merge(df_nodes[['id', 'grid_x', 'grid_y']], left_on='node2', right_on='id', how='left').rename(columns={'grid_x': 'grid_x2', 'grid_y': 'grid_y2'}).drop(columns=['id'])\n",
    "\n",
    "    edges_df = edges_df[(edges_df['grid_x1'] == edges_df['grid_x2']) & (edges_df['grid_y1'] == edges_df['grid_y2'])]\n",
    "\n",
    "    edges_df['grid_x'] = edges_df['grid_x1']\n",
    "    edges_df['grid_y'] = edges_df['grid_y1']\n",
    "\n",
    "    edge_density = edges_df.groupby(['grid_x', 'grid_y']).size().reset_index(name='edge_count')\n",
    "    return edge_density\n",
    "\n",
    "def plot_grid_density(grid_density, city_name, output_folder):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        data=grid_density,\n",
    "        x='grid_x', y='grid_y',\n",
    "        size='edge_count', sizes=(10, 200),\n",
    "        hue='edge_count', palette='viridis',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.title(f\"Netzwerkdichte im 100m-Gitternetz von {city_name}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.legend(title='Anzahl Kanten')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f\"Network_density_scatter_100m_Grid_{city_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def plot_specific_grids(grid_density, city_name, output_folder):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=grid_density,\n",
    "        x='grid_x', y='grid_y',\n",
    "        size='edge_count', sizes=(10, 200),\n",
    "        hue='edge_count', palette='viridis',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    specific_grids = grid_density[grid_density['edge_count'].isin([5, 60])]\n",
    "    \n",
    "    if not specific_grids.empty:\n",
    "        sns.scatterplot(\n",
    "            data=specific_grids,\n",
    "            x='grid_x', y='grid_y',\n",
    "            hue='edge_count', palette={5: 'blue', 60: 'red'},\n",
    "            size='edge_count', sizes=(100, 300),\n",
    "            edgecolor='black',\n",
    "            alpha=1,\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Netzwerkdichte mit markierten Grid-Zellen (5 & 60 Kanten) - {city_name}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.legend(title='Anzahl Kanten')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f\"Network_density_marked_5_60_{city_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "city_folder = \"City_data\"\n",
    "output_folder = \"Density of various places\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for subfolder in ['village', 'town', 'city']:\n",
    "    full_path = os.path.join(city_folder, subfolder)\n",
    "    files = [os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")]\n",
    "\n",
    "    for file in files:\n",
    "        city_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        df = load_from_all_xml(file)\n",
    "\n",
    "        df_nodes = df[df['type'] == 'node']\n",
    "        df_ways = df[df['type'] == 'way']\n",
    "\n",
    "        grid_density = calculate_grid_density(df_nodes, df_ways)\n",
    "\n",
    "        city_output_folder = os.path.join(output_folder, city_name)\n",
    "        os.makedirs(city_output_folder, exist_ok=True)\n",
    "\n",
    "        plot_grid_density(grid_density, city_name, city_output_folder)\n",
    "\n",
    "        plot_specific_grids(grid_density, city_name, city_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel-basierte Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kernel_density(df_nodes, df_ways):\n",
    "    earth_radius = 6371000\n",
    "    df_nodes['x'] = np.radians(df_nodes['longitude']) * np.cos(np.radians(df_nodes['latitude'])) * earth_radius\n",
    "    df_nodes['y'] = np.radians(df_nodes['latitude']) * earth_radius\n",
    "\n",
    "    edges = []\n",
    "    for _, row in df_ways.iterrows():\n",
    "        node_ids = row['node_ids']\n",
    "        if node_ids is not None:\n",
    "            for i in range(len(node_ids) - 1):\n",
    "                edges.append((node_ids[i], node_ids[i + 1]))\n",
    "\n",
    "    edges_df = pd.DataFrame(edges, columns=['node1', 'node2'])\n",
    "    edges_df = edges_df.merge(df_nodes[['id', 'x', 'y']], left_on='node1', right_on='id', how='left').rename(columns={'x': 'x1', 'y': 'y1'}).drop(columns=['id'])\n",
    "    edges_df = edges_df.merge(df_nodes[['id', 'x', 'y']], left_on='node2', right_on='id', how='left').rename(columns={'x': 'x2', 'y': 'y2'}).drop(columns=['id'])    \n",
    "\n",
    "    edges_df['x'] = (edges_df['x1'] + edges_df['x2']) / 2\n",
    "    edges_df['y'] = (edges_df['y1'] + edges_df['y2']) / 2\n",
    "\n",
    "    return edges_df[['x', 'y']]\n",
    "\n",
    "city_folder = \"City_data\"\n",
    "output_folder = \"Density of various places\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "files = []\n",
    "for subfolder in ['village', 'town', 'city']:\n",
    "    full_path = os.path.join(city_folder, subfolder)\n",
    "    files = [os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")]\n",
    "\n",
    "    for file in files:\n",
    "        city_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        df = load_from_all_xml(file)\n",
    "\n",
    "        df_nodes = df[df['type'] == 'node']\n",
    "        df_ways = df[df['type'] == 'way']\n",
    "\n",
    "        density_points = calculate_kernel_density(df_nodes, df_ways)\n",
    "\n",
    "        city_output_folder = os.path.join(output_folder, city_name)\n",
    "        os.makedirs(city_output_folder, exist_ok=True)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.kdeplot(\n",
    "            data=density_points,\n",
    "            x='x', y='y',\n",
    "            fill=True, common_norm=False, alpha=0.5\n",
    "        )\n",
    "        plt.title(f\"Kernel-Dichteschätzung der Netzwerkdichte in {city_name}\")\n",
    "        plt.xlabel(\"x (in Metern)\")\n",
    "        plt.ylabel(\"y (in Metern)\")\n",
    "        plt.tight_layout()\n",
    "        output_file = os.path.join(city_output_folder, f\"Network_density_kde_{city_name}.png\")\n",
    "        plt.savefig(output_file)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswirkungen von wichtigsten Kreuzungen und Straßen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_for_centrality(df):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Knoten mit Positionsdaten hinzufügen\n",
    "    for index, row in df[df['type'] == 'node'].iterrows():  \n",
    "        G.add_node(row['id'], pos=(row['longitude'], row['latitude']))\n",
    "\n",
    "    # Kanten hinzufügen, wobei track-Wege und deren Knoten ausgeschlossen werden\n",
    "    for index, way in df[df['type'] == 'way'].iterrows():\n",
    "        highway_type = way['tagvalue']\n",
    "        if highway_type == 'track':  # Ignoriere track-Wege\n",
    "            continue\n",
    "\n",
    "        node_ids_list = way['node_ids']\n",
    "        if node_ids_list is not None:\n",
    "            filtered_node_ids_list = [node_id for node_id in node_ids_list if G.has_node(node_id)]\n",
    "            if len(filtered_node_ids_list) > 1:\n",
    "                for i in range(len(filtered_node_ids_list) - 1):\n",
    "                    G.add_edge(filtered_node_ids_list[i], filtered_node_ids_list[i + 1])\n",
    "\n",
    "    # Entferne Knoten, die nur an 'track' angeschlossene Wege haben\n",
    "    nodes_to_remove = []\n",
    "    for node in G.nodes:\n",
    "        if all(G.get_edge_data(node, neighbor).get('highway_type', '') == 'track' for neighbor in G.neighbors(node)):\n",
    "            nodes_to_remove.append(node)\n",
    "\n",
    "    G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    largest_component = max(nx.connected_components(G), key=len)\n",
    "    G = G.subgraph(largest_component).copy()\n",
    "\n",
    "    return G  \n",
    "\n",
    "def calculate_centrality_indices(G):\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "    return {\n",
    "        'Degree_centrality': degree_centrality,\n",
    "        'Closeness_centrality': closeness_centrality,\n",
    "        'Betweenness_centrality': betweenness_centrality,\n",
    "    }\n",
    "\n",
    "def visualize_centrality(G, centrality, title, output_folder):\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    nodes = nx.draw_networkx_nodes(G, pos, node_size=5, cmap=plt.cm.plasma,\n",
    "                                   node_color=list(centrality.values()), alpha=0.8)\n",
    "    edges = nx.draw_networkx_edges(G, pos, edge_color='grey', alpha=0.5)\n",
    "\n",
    "    # Hinzufügen der Farbskala\n",
    "    cbar = plt.colorbar(nodes)\n",
    "    cbar.set_label('Centrality Value')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(output_folder, f\"{title.replace(' ', '_')}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def get_top_betweennes_centrality_nodes(centrality, top_n):\n",
    "    return sorted(centrality.items(), key=lambda item: item[1], reverse=True)[:top_n]\n",
    "\n",
    "def get_top_closeness_centrality_nodes(centrality, top_n):\n",
    "    return sorted(centrality.items(), key=lambda item: item[1], reverse=True)[:top_n]\n",
    "\n",
    "def calculate_average_shortest_path_length(G):\n",
    "    if not nx.is_connected(G):\n",
    "        G = G.subgraph(max(nx.connected_components(G), key=len)).copy()\n",
    "    return nx.average_shortest_path_length(G)\n",
    "\n",
    "def calculate_number_of_components(G):\n",
    "    return nx.number_connected_components(G)\n",
    "\n",
    "def remove_nodes(G, nodes_to_remove):\n",
    "    G_removed = G.copy()\n",
    "    G_removed.remove_nodes_from(nodes_to_remove)\n",
    "    return G_removed\n",
    "\n",
    "def get_component_sizes(G):\n",
    "    components = list(nx.connected_components(G))\n",
    "    component_sizes = [(len(comp), G.subgraph(comp).number_of_edges()) for comp in components]\n",
    "    return component_sizes\n",
    "\n",
    "def visualize_centrality_comparison(G_original, G_removed, centrality_original, centrality_removed, title, output_folder):\n",
    "    pos = nx.get_node_attributes(G_original, 'pos')\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Original {title}\")\n",
    "    nx.draw(G_original, pos, node_size=10, cmap=plt.cm.plasma,\n",
    "            node_color=list(centrality_original.values()), alpha=0.8, with_labels=False, edge_color='grey')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"After Removal {title}\")\n",
    "    nx.draw(G_removed, pos, node_size=10, cmap=plt.cm.plasma,\n",
    "            node_color=list(centrality_removed.values()), alpha=0.8, with_labels=False, edge_color='grey')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.savefig(os.path.join(output_folder, f\"{title.replace(' ', '_')}_comparison.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def visualize_comparison_metrics(city_names, original_counts, new_counts, metric_name, output_folder, filename):\n",
    "    x = range(len(city_names))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(x, original_counts, width=0.4, label=f'Original {metric_name}', align='center')\n",
    "    plt.bar(x, new_counts, width=0.4, label=f'New {metric_name}', align='edge')\n",
    "    plt.xticks(x, city_names, rotation=45)\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f'Comparison of {metric_name}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f\"{filename}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darstellung der Zentralitäten pro Stadt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_folder = \"City_data\"\n",
    "output_base_folder = \"Node centrality\"\n",
    "\n",
    "collected_data = []\n",
    "\n",
    "top_n_map = {\n",
    "    'village': 10,\n",
    "    'town': 20,\n",
    "    'city': 30\n",
    "}\n",
    "\n",
    "for subfolder in ['village', 'town', 'city']:\n",
    "    full_path = os.path.join(city_folder, subfolder)\n",
    "    files = [os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")]\n",
    "    top_n = top_n_map[subfolder]\n",
    "    for file_path in files:\n",
    "        city_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_folder = os.path.join(output_base_folder, city_name)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        print(f\"Processing {city_name}...\") \n",
    "\n",
    "        df = load_from_all_xml(file_path)\n",
    "        G = create_graph_for_centrality(df)\n",
    "        centrality_indices = calculate_centrality_indices(G)\n",
    "\n",
    "        top_nodes_between = get_top_betweennes_centrality_nodes(centrality_indices['Betweenness_centrality'], top_n=top_n)\n",
    "        top_nodes_close = get_top_closeness_centrality_nodes(centrality_indices['Closeness_centrality'], top_n=top_n)\n",
    "        for node_id, centrality_value in top_nodes_between:\n",
    "            collected_data.append({'city': city_name, 'node_id': node_id, 'Betweenness_centrality': centrality_value})\n",
    "\n",
    "        for node_id, centrality_value in top_nodes_close:\n",
    "            collected_data.append({'city': city_name, 'node_id': node_id, 'Closeness_centrality': centrality_value})\n",
    "\n",
    "        for centrality_name, centrality_values in centrality_indices.items():\n",
    "            visualize_centrality(G, centrality_values, centrality_name.replace(\"_\", \" \").title(), output_folder)\n",
    "\n",
    "top_nodes_df = pd.DataFrame(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergleich vor und nach Löschen der Top-Knoten (Betweenness und Closeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hauptlogik\n",
    "city_folder = \"City_data\"\n",
    "output_base_folder = \"Node centrality\"\n",
    "\n",
    "city_names = []\n",
    "original_component_counts = []\n",
    "new_component_counts = []\n",
    "original_asp_lengths = []\n",
    "new_asp_lengths = []\n",
    "\n",
    "top_n_map = {\n",
    "    'village': 10,\n",
    "    'town': 20,\n",
    "    'city': 30\n",
    "}\n",
    "\n",
    "for subfolder in ['village', 'town']:\n",
    "    full_path = os.path.join(city_folder, subfolder)\n",
    "    files = [os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")]\n",
    "    for file_path in files:\n",
    "        city_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_folder = os.path.join(output_base_folder, city_name)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        print(f\"Processing {city_name}...\")    \n",
    "        df = load_from_all_xml(file_path)\n",
    "\n",
    "        G = create_graph_for_centrality(df)\n",
    "        centrality_indices_original = calculate_centrality_indices(G)\n",
    "\n",
    "        original_component_count = calculate_number_of_components(G)\n",
    "        original_asp_length = calculate_average_shortest_path_length(G)\n",
    "\n",
    "        # Top-K Knoten der Betweenness-Zentralität\n",
    "        top_nodes_between = get_top_betweennes_centrality_nodes(centrality_indices_original['Betweenness_centrality'], top_n=top_n_map[subfolder])\n",
    "        nodes_to_remove = [node_id for node_id, _ in top_nodes_between]\n",
    "\n",
    "        G_removed = remove_nodes(G, nodes_to_remove)\n",
    "        centrality_indices_removed = calculate_centrality_indices(G_removed)\n",
    "\n",
    "        new_component_count = calculate_number_of_components(G_removed)\n",
    "        new_asp_length = calculate_average_shortest_path_length(G_removed)\n",
    "\n",
    "        component_sizes_removed = get_component_sizes(G_removed)\n",
    "\n",
    "        # Ausgabe der Anzahl der Knoten und Kanten pro Komponente\n",
    "        print(f\"Component sizes after node removal for {city_name}:\")\n",
    "        for i, (num_nodes, num_edges) in enumerate(component_sizes_removed):\n",
    "            print(f\"  Component {i+1}: {num_nodes} nodes, {num_edges} edges\")\n",
    "\n",
    "        city_names.append(city_name)\n",
    "        original_component_counts.append(original_component_count)\n",
    "        new_component_counts.append(new_component_count)\n",
    "        original_asp_lengths.append(original_asp_length)\n",
    "        new_asp_lengths.append(new_asp_length)\n",
    "\n",
    "        # Visualisierung der zentralen Knoten\n",
    "        visualize_centrality_comparison(\n",
    "            G, G_removed,\n",
    "            centrality_indices_original['Betweenness_centrality'],\n",
    "            centrality_indices_removed['Betweenness_centrality'],\n",
    "            'Betweenness Centrality',\n",
    "            output_folder\n",
    "        )\n",
    "\n",
    "# Vergleichsmetriken visualisieren\n",
    "visualize_comparison_metrics(city_names, original_component_counts, new_component_counts, \n",
    "                             'Number of Components', output_base_folder, \"Number_of_components_Betweenness\")\n",
    "visualize_comparison_metrics(city_names, original_asp_lengths, new_asp_lengths, \n",
    "                             'ASP Lengths', output_base_folder, \"ASP_lengths_Betweenness\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_folder = \"City_data\"\n",
    "output_base_folder = \"Node centrality\"\n",
    "\n",
    "city_names = []\n",
    "original_component_counts = []\n",
    "new_component_counts = []\n",
    "original_asp_lengths = []\n",
    "new_asp_lengths = []\n",
    "\n",
    "top_n_map = {\n",
    "    'village': 10,\n",
    "    'town': 20,\n",
    "    'city': 30\n",
    "}\n",
    "\n",
    "for subfolder in ['village', 'town']:\n",
    "    full_path = os.path.join(city_folder, subfolder)\n",
    "    files = [os.path.join(full_path, file) for file in os.listdir(full_path) if file.endswith(\".osm\")]\n",
    "    for file_path in files:\n",
    "        city_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_folder = os.path.join(output_base_folder, city_name)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        print(f\"Processing {city_name}...\")    \n",
    "        df = load_from_all_xml(file_path)\n",
    "\n",
    "        G = create_graph_for_centrality(df)\n",
    "        centrality_indices_original = calculate_centrality_indices(G)\n",
    "\n",
    "        original_component_count = calculate_number_of_components(G)\n",
    "        original_asp_length = calculate_average_shortest_path_length(G)\n",
    "\n",
    "        # Top-K Knoten der Closeness-Zentralität\n",
    "        top_nodes_between = get_top_closeness_centrality_nodes(centrality_indices_original['Closeness_centrality'], top_n=top_n_map[subfolder])\n",
    "        nodes_to_remove = [node_id for node_id, _ in top_nodes_between]\n",
    "\n",
    "        G_removed = remove_nodes(G, nodes_to_remove)\n",
    "        centrality_indices_removed = calculate_centrality_indices(G_removed)\n",
    "\n",
    "        new_component_count = calculate_number_of_components(G_removed)\n",
    "        new_asp_length = calculate_average_shortest_path_length(G_removed)\n",
    "\n",
    "        component_sizes_removed = get_component_sizes(G_removed)\n",
    "\n",
    "        # Ausgabe der Anzahl der Knoten und Kanten pro Komponente\n",
    "        print(f\"Component sizes after node removal for {city_name}:\")\n",
    "        for i, (num_nodes, num_edges) in enumerate(component_sizes_removed):\n",
    "            print(f\"  Component {i+1}: {num_nodes} nodes, {num_edges} edges\")\n",
    "\n",
    "\n",
    "        city_names.append(city_name)\n",
    "        original_component_counts.append(original_component_count)\n",
    "        new_component_counts.append(new_component_count)\n",
    "        original_asp_lengths.append(original_asp_length)\n",
    "        new_asp_lengths.append(new_asp_length)\n",
    "\n",
    "        # Visualisierung der zentralen Knoten\n",
    "        visualize_centrality_comparison(\n",
    "            G, G_removed,\n",
    "            centrality_indices_original['Closeness_centrality'],\n",
    "            centrality_indices_removed['Closeness_centrality'],\n",
    "            'Closeness Centrality',\n",
    "            output_folder\n",
    "        )\n",
    "\n",
    "# Vergleichsmetriken visualisieren\n",
    "visualize_comparison_metrics(city_names, original_component_counts, new_component_counts, \n",
    "                             'Number of Components', output_base_folder, \"Number_of_components_Closeness\")\n",
    "visualize_comparison_metrics(city_names, original_asp_lengths, new_asp_lengths, \n",
    "                             'ASP Lengths', output_base_folder, \"ASP_lengths_Closeness\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
